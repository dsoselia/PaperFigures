Shiyuan Huang
Siddarth Mamidanna
Shreedhar Jangam
Yilun Zhou
Leilani H. Gilpin
UC Santa Cruz
UC Santa Cruz
UC Santa Cruz
MIT CSAIL
UC Santa Cruz
{shuan101, spmamida, sjangam}@ucsc.edu, yilun@csail.mit.edu, lgilpin@ucsc.edu
Abstract—Large language models (LLMs) such as ChatGPT
have demonstrated superior performance on a variety of natural
language processing (NLP) tasks including sentiment analysis,
mathematical reasoning and summarization. Furthermore, since
these models are instruction-tuned on human conversations
to produce “helpful” responses, they can and often will pro-
duce explanations along with the response, which we call self-
explanations. For example, when analyzing the sentiment of a
movie review, the model may output not only the positivity of the
sentiment, but also an explanation (e.g., by listing the sentiment-
laden words such as “fantastic” and “memorable” in the review).
How good are these automatically generated self-explanations?
In this paper, we investigate this question on the task of sentiment
l
i
d f
f
t
tt ib ti
l
ti
f th
t
This review is very positive, as
judged by the positive words
“fantastic” and “terrific”.
Is this review positive? Why or why not? 
“A fantastic movie directed by the famous 
Lucas Johnson, who has a track-record of 
producing terrific novel adaptions.”
Comprehensiveness/
Sufficiency/
Rank Correlation
17 Oct 2023