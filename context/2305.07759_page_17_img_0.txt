precisely, we take S as the entire training corpus, for each r ∈ Gk({Ti}i∈[100]) we measure
gr :=
�
q∈Gk(S) 1gr=q
| �
q∈Gk(S) |
In other words, for each k-gram generated by the model, we measure the frequency that it appears in the
original training dataset, where gr = 0 means that the k-gram never appears in the training dataset.
4. How similar is the generated story to the closest point, in terms of Rouge precision score, in the entire dataset.
Let S1, S2, · · · , Sm be all the stories in the training dataset, in Figure 17, we compute
hi = max
j∈[m] R2,p(Ti, Sj)
Figure 14: Rogue2 (precision) score between the model’s completion and the original story from the same beginnings
(we select 100 from the training dataset). We can see that most of the completions that the models generate are
very different from the ones in the training dataset (and also not subsampled versions of the original ones).
Figure 15: Maximum Rouge2 score (fmeasure) similarity between the 100 generated stories for each model. Here
original model means the ones generated by GPT-3.5.
For the sake of getting a more concrete impression about how different the model completions are from the
original ending of the story and from other stories in the dataset, in Figure 18 we provide one example of the
original story, the alternative completion by our model together with its closest point in the training dataset.
The above points towards several findings:
• When the model generates stories using a diverse set of prompts, it ends up with a diverse set of completions.
18