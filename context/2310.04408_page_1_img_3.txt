encode the documents.
We propose compressors: (1) Extractive compressor which selects relevant sentences from retrieved
document set; (2) Abstractive compressor which generates a summary synthesizing information
from multiple retrieved documents. Both compressors implement multi-document query-focused
summarization (Xu & Lapata, 2020), where we summarize retrieved evidence document set with
respect to the input query. As we aim to enable RALM to generate correct output when summary is
prepended to the input query, we design training schemes to optimize the end task performance. Our
extractive compressor is trained with a contrastive learning objective to identify sentences that lead to
target outputs, and our abstractive compressor is distilled (West et al., 2022) from an extreme-scale
LM (e.g. GPT-3), which achieves impressive summarization performance.
Our experiments show that RECOMP can improve performance of frozen LMs on language model-
ing (Merity et al., 2016) and three question answering datasets (Natural Questions (Kwiatkowski et al.,
2019), TriviaQA (Joshi et al., 2017) and HotpotQA (Yang et al., 2018)), while prepending significantly
fewer tokens compared to RALM without compression. We present two oracle compression methods
â€“ an extractive oracle which selects a sentence in evidence documents that leads to the best task
performance and an abstractive oracle which chooses between a summary generated by extreme-scale
LLM (e.g. GPT-3) and no retrieval augmentation that leads to the best task performance. Both oracle
methods achieve a compression rate as low as 6% and significantly outperforms prepending full
documents. Our trained compressors also show promising results. For language modelling, both
trained compressors achieve a compression ratio of 25% with minimal performance drop. When
applied to QA datasets, our best model compresses the documents to 5 - 10% of the original tokens