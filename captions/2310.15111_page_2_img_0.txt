Technical report. In progress
Figure 2: An illustration of Matryoshka Diffusion.
zL
t , zM
t
and zH
t
are noisy images at three different
resolutions, which are fed into the denoising network together, and predict targets independently.
noise- or v-prediction (Salimans & Ho, 2022) for improved performance. Unlike other generative
models like GANs (Goodfellow et al., 2014), diffusion models require repeatedly applying a deep
neural network xθ in the ambient space as enough computation with global interaction is crtical for
denoising (Kadkhodaie et al., 2022). This makes it challenging to design efficient diffusion models
directly for high-resolution generation, especially for complex tasks like text-to-image synthesis. As
common solutions, existing methods have focused on learning hierarchical generation:
Cascaded diffusion (Ho et al., 2022b; Ramesh et al., 2022; Saharia et al., 2022; Ho et al.,
2022a)
utilize a cascaded approach where a first diffusion model is used to generate data at lower
resolution, and then a second diffusion model is used to generate a super-resolution version of the
initial generation, taking the first stage generation as conditioning. Cascaded models can be chained
multiple times until they reach the final resolution. Ho et al. (2022a); Singer et al. (2022) uses
a similar approach for video synthesis as well – models are cascaded from low spatio-temporal
resolution to high spatio-temporal resolution. However, since each model is trained separately, the
generation quality can be bottlenecked by the exposure bias (Bengio et al., 2015) from imperfect
predictions and several models need to be trained corresponding to different resolutions.
Latent diffusion (LDM, Rombach et al., 2022)
and its follow-ups (Peebles & Xie, 2022; Xue et al.,
2023; Podell et al., 2023), on the other hand, handle high-resolution image generation by performing
diffusion in the lower resolution latent space of a pre-trained auto-encoder, which is typically trained
with adversarial objectives (Esser et al., 2021). This not only increases the complexity of learning,
but bounds the generation quality due to the lossy compression process.
End-to-end models
Recently, several approaches have been proposed (Hoogeboom et al., 2023;
Jabri et al., 2022; Chen, 2023) to train end-to-end models directly on high-resolution space. Without
relying on separate models, these methods focus on efficient network design as well as shifted noise
schedule to adapt high-resolution spaces. Nevertheless, without fully considering the innate structure
of hierarchical generation, their results lag behind cascaded and latent models.
3
Matryoshka Diffusion Models
In this section, we present Matryoshka Diffusion Models (MDM), a new class of diffusion models
that is trained end-to-end in high-resolution space, while exploiting the hierarchical structure of data
formation. MDM first generalizes standard diffusion models in the extended space (§ 3.1), for which
specialized nested architectures (§ 3.2) and training procedures (Appendix B) are proposed.
3.1
Diffusion Models in Extended Space
Unlike cascaded or latent methods, MDM learns a single diffusion process with hierarchical structure
by introducing a multi-resolution diffusion process in an extended space. An illustration is shown
in Fig. 2. Given a data point x ∈ RN, we define time-dependent latent zt =
�
z1
t , . . . , zR
t
�
∈
RN1+...NR. Similar to Eq. (1), for each zr, r = 1, . . . , R:
q(zr
t |x) = N(zr
t ; αr
tDr(x), σr
t
2I),
(2)
3