Ours
SD2
Ours
SD2
Ours
SD2
ice princess
Snoopy
a adventurous archaeologist with
a whip and a fedora
A teenage wizard with round
glasses
a cartoon beagle in a red dog
house
black and white stencil little
girl reaching for a red balloon
Figure 10: We compare CommonCanvas-SNC (Ours) to SD2. Our model is less likely to generate
iconic characters given suggestive prompts (drawn from Lee et al. [29]).
drop in performance is not as dramatic as one might assume. Moreover, we speculate that it would if
users were to supplement with their own datasets, like FFHQ [22], if they seek to fine-tune models
for specific categories.
6.2
Human evaluation
While automated quality metrics are useful, given the level of detail and breadth of of the distribution
large T2I are intended to generate, there is no substitute for evaluation by human raters. Human
pairwise preference ratings for the three 512x512 resolution CommonCanvas models compared to
SD2-base can be seen in Figure 7.
In this experiment, human raters were shown a prompt (selected randomly from the PartiPrompts
prompts set [66]) along with two generated images in randomized order, one from the reference
model (SD2-base) and the other from a CommonCanvas model. Users were asked which generated
image they preferred. We report the fraction of the time users selected the image generated by the
CommonCanvas model over the corresponding generation from SD2 as the user preference rate for
that model. In agreement with our automated quality metrics, we find that the two small Common-
Canvas models are less perferred than SD2-base, with preference rates of 37% for CommonCanvas-
SC and 38% for CommonCanvas-SNC, which we find surprisingly high considering the smaller and
synthetic nature of the dataset. For the largest model, CommonCanvas-LNC, we do not measure
a statistically significant difference in user preference between this model and SD2-base. While
SDXL is a significantly larger model, this finding represents an existential result, showing that we
are capable of matching the performance of a model trained on several magnitudes more of data.
6.3
Benefits and challenges of synthetic captions
Interestingly, we observe that synthetic captions can enhance the alignment of our model. For in-
stance, the CLIP Score for synthetic captions exceeded that of ground-truth captions as seen in
Figure 8.
We also observed reduced diversity of n-grams in our synthetic captions, a pattern previously noted
by Nguyen et al. [42]. This effect can be visualized through the decrease in unique trigrams.
Although we train on Creative-Commons images, it is still possible for an adversarial prompt to
produce content that, for example, includes iconic characters. In Figure 10, we subject our model
to ambiguous prompts that are suggestive of such characters. Examples include visuals closely
resembling Elsa from Frozen, Indiana Jones resembling Harrison Ford, and even a likeness to Harry
Potter (Figure 10). Qualitatively, our model deviated more from these characters than SD2.
9