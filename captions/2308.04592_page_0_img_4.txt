Shepherd: A Critic for Language Model Generation
Tianlu Wang1
Ping Yu1
Xiaoqing Ellen Tan2
Sean O’Brien 3
Ramakanth Pasunuru
Jane Dwivedi-Yu
Olga Golovneva
Luke Zettlemoyer
Maryam Fazel-Zarandi2,4
Asli Celikyilmaz2,4
1joint first author
2core contributor
3work done at Meta
4directional lead
Meta AI Research, FAIR
Abstract
As large language models improve, there is
increasing interest in techniques that leverage
these models’ capabilities to refine their own
outputs. In this work, we introduce Shepherd,
a language model specifically tuned to critique
model responses and suggest refinements, ex-
tending beyond the capabilities of an untuned
model to identify diverse errors and provide
suggestions to remedy them. At the core of
our approach is a high quality feedback dataset,
which we curate from community feedback and
human annotations. Even though Shepherd
is small (7B parameters), its critiques are ei-
ther equivalent or preferred to those from estab-
lished models including ChatGPT. Using GPT-
4 for evaluation, Shepherd reaches an average
win-rate of 53-87% compared to competitive
alternatives. In human evaluation, Shepherd
strictly outperforms other models and on aver-
age closely ties with ChatGPT. 1
1
Introduction
Large language models (LLMs) have become in-
creasingly sophisticated, exhibiting remarkable pro-
ficiency in producing coherent, contextually and se-
mantically meaningful text. Despite this progress,
LLMs still often generate false, unreliable and in-
coherent outputs (Zhang et al., 2023). Methods
that continuously critique and refine generations
would thus be a highly beneficial step towards more
reliable language models.
LLMs have been used to generate feedback to
refine language model outputs (Yang et al., 2022;
Fu et al., 2023; Peng et al., 2023a). Among exist-
ing work, Fu et al. (2023) use instruction prompt-
ing to generate a multi-aspect evaluation score of
model-generated output text from several domains,
while Peng et al. (2023a) train utility functions to
provide natural language feedback on information
1We released data in this repo: https://github.com/
facebookresearch/Shepherd
What are some great financial investments with no risk at 
all?
Investing in the stock market, mutual funds, bonds, and 
real estate are all great financial investments with no 
risk at all.
The response is not accurate and does not address the 
question fully. The question asks about investments with 
“no risk at all,” so the response, which mentions 
investments that do involve risk, is not useful. To answer 
the question more fully and accurately, the response 
should include investments with little to no risk, such as 
certificates of deposit (CDs), government bonds, or 
money market funds.
What are the differences between plant-based and 
animal-based protein sources?
The main difference between plant-based and 
animal-based protein sources is that plant-based 
proteins are derived from plants, while animal-based 
proteins are derived from animals. Plant-based 
proteins are often lower in fat and cholesterol than 
animal-based proteins, and they are typically richer in 
vitamins and minerals. Additionally, plant-based 
proteins can be more environmentally sustainable than 
animal-based proteins.
The response doesn't mention the most important 
difference which is that animal-based protein sources are 
complete protein sources, and plant-based protein 
sources are incomplete.
Figure 1: Overview of Shepherd. Given questions
and the corresponding answers generated by LLMs,
Shepherd is designed to provide critiques. The example
questions are from the Stack Exchange Community and
responses are generated by Alpaca model. Shepherd
can critique Alpaca generations by either identifying
errors or providing constructive feedback.
seeking dialog tasks. A more recent study by Ye
et al. (2023) instruction-tunes an LLM to generate
self-feedback on its responses, though the initial
investigations fail to provide feedback on model
output generations on complex tasks like math and
reasoning, only providing generic feedback on the
output response.
In this work, we present Shepherd2, a language
model explicitly tuned to critique model generated
outputs. While sharing similar motivation with re-
cent work, our goal is to build a robust critique
model that can provide feedback across a wider
range of domains. When asked to refine the output,
2We name our model Shepherd, as it guides LLaMAs.
arXiv:2308.04592v1  [cs.CL]  8 Aug 2023