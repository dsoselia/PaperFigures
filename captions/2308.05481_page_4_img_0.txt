Figure 3: The outline of diagnosis experience extracted from documents.
Figure 4: Example LLM diagnosis by tree of thought
Step3: Existing Node Reflection. For each node in the path from the
root node to the selected node, reflections are generated based on
decisions made at previous nodes. For example, we count on LLM
to rethink the benefits of analyzing non-resource relevant metrics.
If LLM decides the action cannot find any useful information, the
UCT value will be reduced and set to that of its parent node. In this
way, we can enhance the diagnosis efficiency.
Step4: Terminal Condition. If LLM cannot find any more root
cause (corresponding to a leaf node) for a threshold time (e.g., five),
the algorithm ends and LLM outputs the final analysis based on the
detected root causes.
8
COLLABORATIVE DIAGNOSIS FOR
COMPLEX CASES
A single LLM may be limited in its ability to fully resolve a problem
(e.g., stuck in initial steps). Collaborative diagnosis involves the
utilization of multiple LLMs to collectively address complex cases
by leveraging their unique role capabilities. This section introduces
the communicative framework for database diagnosis [1, 16].
• Agents. In the communicative framework, agents can be
undertaken by human beings or LLMs. Humans can pro-
vide LLM agents with scenario requirements (e.g., business
changes over the incoming period) and prior knowledge (e.g.,
historical anomalies). On the other hand, each LLM agent
is dedicated to a distinct domain of functions. For example,
we include three LLM agents in the initial implementation:
(1) Chief DBA is responsible for collaboratively diagnosing
and detecting root causes with other agents; (2) CPU Agent
is specialized in CPU usage analysis and diagnosis, and (3)
Memory Agent focuses on memory usage analysis and diag-
nosis. Each LLM agent can automatically invoke tool APIs to
retrieve database statistics, extract external knowledge, and
conduction optimizations. For instance, CPU Agent utilizes
the monitoring tool Prometheus to check CPU usage metrics
within specific time periods, and determine the root causes
of high CPU usage by matching with extracted experience
(Section 4). Note, if CPU/memory agents cannot report useful
analysis, Chief DBA is responsible to detect other potential
problems, such as those on the application side.
• Environment Settings. We need to set a series of principles
for the agents to efficiently communicate, such as (1) Chat
Order: To avoid the mutual negative influence, we only al-
low one LLM agent to “speak” (i.e., appending the analysis
results to the chat records to let other agents know) at a
time. To ensure flexible chat (e.g., if an agent cannot detect
anything useful, it should not speak), we rely on Chief DBA
to decide which agent to speak in each iteration (diagnosis
scheduling); (2) Visibility: By default, we assume the analysis
results of agents can be seen by each other, i.e., within the
same chat records. In the future, we can split agents into
different groups, where each group is in charge of different
database clusters/instances and they do not share the chat
records; (3) Selector is vital to filter invalid analysis that may
mislead the diagnosis directions; (4) Updater works to update
agent memory based on the historical records.
• Chat Summary . For a complex database problem, it re-
quires agents dozens of iterations to give in-depth analy-
sis, leading to extremely long chat records. Thus, it is vi-
tal to effectively summarize the critical information from
chat records without exceeding the maximal length of LLM
prompts. To the end, we progressively summarize the lines
5