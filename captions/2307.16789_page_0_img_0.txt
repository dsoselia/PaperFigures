MODELS TO MASTER 16000+ REAL-WORLD APIS
Yujia Qin1∗, Shihao Liang1∗, Yining Ye1, Kunlun Zhu1, Lan Yan1, Yaxi Lu1, Yankai Lin3†,
Xin Cong1, Xiangru Tang4, Bill Qian4, Sihan Zhao1, Lauren Hong1, Runchu Tian1,
Ruobing Xie5, Jie Zhou5, Mark Gerstein4, Dahai Li2,6, Zhiyuan Liu1†, Maosong Sun1†
1Tsinghua University 2ModelBest Inc. 3Renmin University of China
4Yale University 5WeChat AI, Tencent Inc. 6Zhihu Inc.
yujiaqin16@gmail.com
ABSTRACT
Despite the advancements of open-source large language models (LLMs), e.g.,
LLaMA, they remain significantly limited in tool-use capabilities, i.e., using exter-
nal tools (APIs) to fulfill human instructions. The reason is that current instruction
tuning largely focuses on basic language tasks but ignores the tool-use domain.
This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA)
closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM,
a general tool-use framework encompassing data construction, model training,
and evaluation. We first present ToolBench, an instruction-tuning dataset for tool
use, which is constructed automatically using ChatGPT. Specifically, the con-
struction can be divided into three stages: (i) API collection: we collect 16, 464
real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruc-
tion generation: we prompt ChatGPT to generate diverse instructions involving
these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path
annotation: we use ChatGPT to search for a valid solution path (chain of API
calls) for each instruction. To enhance the reasoning capabilities of LLMs, we
develop a novel depth-first search-based decision tree algorithm. It enables LLMs
to evaluate multiple reasoning traces and expand the search space. Moreover,
to evaluate the tool-use capabilities of LLMs, we develop an automatic evalu-
ator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM
ToolLLaMA, and equip it with a neural API retriever to recommend appropriate
APIs for each instruction. Experiments show that ToolLLaMA demonstrates a
remarkable ability to execute complex instructions and generalize to unseen APIs,
and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demon-
strates strong zero-shot generalization ability in an out-of-distribution tool-use
dataset: APIBench. The codes, trained models, and demo are publicly available at
https://github.com/OpenBMB/ToolBench.
1
INTRODUCTION
Tool learning (Qin et al., 2023b) aims to unleash the power of large language models (LLMs) to effec-
tively interact with various tools (APIs) to accomplish complex tasks. By integrating LLMs with APIs,
we can greatly expand their utility and empower them to serve as efficient intermediaries between
users and the vast ecosystem of applications. Although open-source LLMs, e.g., LLaMA (Touvron
et al., 2023a), have achieved versatile capabilities through instruction tuning (Taori et al., 2023;
Chiang et al., 2023), they still lack the sophistication in performing higher-level tasks, such as appro-
priately interacting with tools (APIs) to fulfill complex human instruction. This deficiency is because
current instruction tuning largely focuses on basic language tasks, with a relative neglect of the
tool-use domain. On the other hand, current state-of-the-art (SOTA) LLMs (e.g., ChatGPT (OpenAI,
∗ Indicates equal contribution.
† Corresponding author.
1
arXiv:2307.16789v2  [cs.AI]  3 Oct 2023