the context of the prompt for generation. Table 1 shows the statistics of the top N retrieved chunks
while Figure 1 gives more details of the token length distribution of all seven datasets. Note that,
some dataset like Qasper (QASP) is relatively short and donâ€™t have up to 20 chunks, so the average
length of top-10 chunks and top-20 chunks are close. We can see that top-5 chunks can all fit into
4k sequence length (except few outliers) while top-10 and top-20 chunks can fit into 16k sequence
length.
3.5
INSTRUCTION TUNING
To train the pretrained LLMs to follow instructions for question answering or text summarization, we
also performed instruction tuning We first construct a blend of instruction tuning datasets consisting