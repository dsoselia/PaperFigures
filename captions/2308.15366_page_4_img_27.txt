3.3. Data for image-text alignment
Anomaly Simulation We primarily adopt the approach
proposed by NSA [24] to simulate anomalous data. The
NSA [24] method builds upon the Cut-paste [14] technique
by incorporating the Poisson image editing [20] method
to alleviate the discontinuity introduced by pasting image
segments. Cut-paste [14] is a common technique in IAD
domain for generating simulated anomaly images.
This
method involves randomly cropping a block region from an
image and then pasting it onto a random location in another
image, thus creating a simulated anomalous portion. Sim-
ulated anomaly samples can significantly enhance the per-
formance of IAD models, but this procedure often results
in noticeable discontinuities, as illustrated in Figure 3. The
Poisson editing method [20] has been developed to seam-
lessly clone an object from one image into another image
by solving the Poisson partial differential equations.
Figure 3. Illustration of the comparison between cut-paste and
poisson image editing. The results of cut-paste exhibit evident
discontinuities and the results of poisson image editing are more
natural.
Question and Answer Content To conduct prompt tuning
on the LVLM, we generate corresponding textual queries
based on the simulated anomalous images.
Specifically,
each query consists of two components. The first part in-
volves a description of the input image, providing infor-
mation about the objects present in the image and their ex-
pected attributes, such as This is a photo of leather, which
should be brown and without any damage, flaw, defect,
scratch, hole or broken part. The second part queries the
presence of anomalies within the object, namely Is there
any anomaly in the image? The LVLM firstly responds to
whether anomalies are present. If anomalies are detected,
the model continues to specify the number and location of
the anomalous areas, such as Yes, there is an anomaly in
the image, at the bottom left of the image. or No, there
are no anomalies in the image. We divide the image into
a grid of 3 × 3 distinct regions to facilitate the LVLM in
verbally indicating the positions of anomalies, as shown in
Figure 4. The descriptive content about the image furnishes
the LVLM with foundational knowledge of the input im-
age, aiding in the model’s better comprehension of the im-
age contents. However, during practical applications, users
may opt to omit this descriptive input, and the model is still
capable of performing IAD task based solely on the pro-
vided image input. Detailed description for each category
are provided in Appendix C.
Figure 4. Illustration of the 3 × 3 grid of image, which is used to
let LLM verbally indicate the abnormal position.
Prompts fed to the LLM typically follow the format:
### Human: <Img>Eimg</Img>Eprompt[Image De-
scription]Is there any anomaly in the image?###Assistant:
Eimg ∈ RCemb represents the image embedding be-
ing processed through the image encoder and linear layer,
Eprompt ∈ R(n1+n2)×Cemb refers to the prompt embed-
dings generated by the prompt learner, and [Image Descrip-
tion] corresponds to the textual description of the image.
3.4. Loss Functions
To train the decoder and prompt learner, we primarily
employed three loss functions: cross-entropy loss, focal
loss [16], and dice loss [18]. The latter two are primarily
utilized to enhance the pixel-level localization accuracy of
the decoder.
Cross-entropy Loss Cross-entropy loss is commonly em-
ployed for training language models, which quantifies the
disparity between the text sequence generated by the model
and the target text sequence. The formula is as follows:
Lce = −
n
�
i=1
yilog(pi),
(3)
where n is the number of tokens, yi is the true label for
token i and pi is the predicted probability for token i.
Focal Loss Focal loss [16] is commonly used in object de-
tection and semantic segmentation to address the issue of
class imbalance, which introduces an adjustable parameter
γ to modify the weight distribution of cross-entropy loss,
emphasizing samples that are difficult to classify. In IAD
task, where most regions in anomaly images are still nor-
mal, employing focal loss can mitigate the problem of class
imbalance. Focal loss can be calculated by Eq. (4):
Lfocal = − 1
n
n
�
i=1
(1 − pi)γlog(pi),
(4)
5