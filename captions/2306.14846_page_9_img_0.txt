consider the same CARLA driving task but with two different high-level planners: (i) a position-
based planner that commands a sequence of GPS waypoints, and (ii) a routing planner with similar
functionality to Google Maps that commands high-level navigation directions (left/right/straight) to
the policy [22]. We compare the pre-trained navigational priors learned by ViNT to the baselines
discussed earlier, corresponding to pre-trained visual representations and policies, each adapted to
the downstream task using the same on-task data (see Appendix E.3 for more details).
Table 3 summarizes our results for the two tasks. We again find that general pre-trained visual rep-
resentations, such as ImageNet or VC-1, are not sufficient to extract navigational affordances for
challenging downstream tasks, suggesting that effective generalization requires more than general
visual representations [44, 45]. We also find that unlike fine-tuning, GNM [19] struggles with the
adaptation task, suggesting that the architecture and increased capacity of ViNT are essential for
broad generalization and adaptation. ViNT achieves strong performance on both tasks, demonstrat-
ing its ability to serve as a foundation model for downstream tasks.
6.5
Emergent Behaviors
One of the most exciting aspects of large-scale machine learning is the potential for emergent be-
havior that arises from the training of large models on diverse datasets. Despite the simple self-
supervised training objective used by ViNT (Equation 1), it shows a number of emergent behaviors,
which we describe qualitatively in this section and present as examples on the project page and
supplemental videos: general-navigation-models.github.io.
Figure 9: Samples from the diffusion model may be invalid subgoals,
but ViNT is robust to such proposals.
Implicit
navigation
affor-
dances: Ideally, we would like
a robot foundation model to
exhibit some desirable “default”
behavior,
while
providing
a
mechanism
for
downstream
applications to adapt this be-
havior as needed. We find that
ViNT has this property vis-a-vis
collision-avoidance. One piece
of evidence is its behavior when provided with random subgoals from locations that are not
reachable by the robot, studied quantatively via the ViNT-R baseline in Table 1. In this case, despite
the subgoals being invalid and out-of-distribution (ViNT was only trained to reach subgoals), ViNT
succeeds at exploring the environment and reaches the goal 80% of the time, outperforming all
baselines. This suggests that ViNT takes collision-free actions when provided with meaningless
goals (i.e. the above “default”), while still attempting to follow reachable subgoals.
Indeed, although the “full” version of our
method augmented with the diffusion model
performs better, the subgoals generated by this
model are often of low quality with many ar-
tifacts, and sometimes do not match any real
reachable state (Figure 9).
Nonetheless, be-
cause of this “default” behavior, ViNT is able
to successfully leverage the valid subgoals,