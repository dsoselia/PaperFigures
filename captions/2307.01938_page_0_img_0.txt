YUTING YE, Reality Labs Research, Meta, United States of America
MICHIEL VAN DE PANNE, University of British Columbia, Canada
ALEXANDER WINKLER, Reality Labs Research, Meta, United States of America
Fig. 1. Our method uses only a headset and controller pose as input to generate a physically-valid pose for a
variety of characters in real-time.
Avatars are important to create interactive and immersive experiences in virtual worlds. One challenge in
animating these characters to mimic a user’s motion is that commercial AR/VR products consist only of a
headset and controllers, providing very limited sensor data of the user’s pose. Another challenge is that an
avatar might have a different skeleton structure than a human and the mapping between them is unclear. In
this work we address both of these challenges. We introduce a method to retarget motions in real-time from
sparse human sensor data to characters of various morphologies. Our method uses reinforcement learning to
train a policy to control characters in a physics simulator. We only require human motion capture data for
training, without relying on artist-generated animations for each avatar. This allows us to use large motion
capture datasets to train general policies that can track unseen users from real and sparse data in real-time. We
demonstrate the feasibility of our approach on three characters with different skeleton structure: a dinosaur, a
mouse-like creature and a human. We show that the avatar poses often match the user surprisingly well, despite
having no sensor information of the lower body available. We discuss and ablate the important components in
our framework, specifically the kinematic retargeting step, the imitation, contact and action reward as well as
our asymmetric actor-critic observations. We further explore the robustness of our method in a variety of
settings including unbalancing, dancing and sports motions.
Authors’ addresses: Daniele Reda, dreda@cs.ubc.ca, University of British Columbia, Canada; Jungdam Won, Seoul National
University, South Korea; Yuting Ye, Reality Labs Research, Meta, United States of America; Michiel van de Panne, University
of British Columbia, Canada; Alexander Winkler, winklera@meta.com, Reality Labs Research, Meta, United States of
America.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the
full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
2577-6193/2023/8-ART $15.00
https://doi.org/10.1145/3606928
Proc. ACM Comput. Graph. Interact. Tech., Vol. 6, No. 2, Article . Publication date: August 2023.
arXiv:2307.01938v1  [cs.CV]  4 Jul 2023