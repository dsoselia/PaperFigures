Brain2Image
Ours
Airliner
Panda
Jack-o’-Lantern
Figure 4: Comparison baseline Brain2Image (Kavasidis et al. 2017) and our proposed NEUROIMAGEN in three classes, namely
’Airliner’, ’Panda’, and ’Jack-o’-Lantern’. The first and second row depicts the results of Brain2Image and our NEUROIMAGEN,
respectively.
Model
B
L
I
ACC(%)
IS
SSIM
1
�
�
�
4.5
16.31
0.234
2
�
�
�
85.9
34.12
0.180
3
�
�
�
74.1
29.87
0.157
4
�
�
�
65.3
25.86
0.235
5
�
�
�
85.6
33.50
0.249
Table 3: Quantitative results of ablation studies. B and L
represent the semantic decoding using BLIP caption and la-
bel caption from EEG signals, respectively. I represents the
perceptual information decoding from EEG signals.
Pixel-level Semantics
To demonstrate the effectiveness of
the pixel-level semantics from EEG signals, we conduct val-
idation on models 2, 3, 4, and 5. By comparing 2 with 5 and
3 with 4, we find that using the pixel-level semantics, i.e. the
saliency map, can significantly increase the structure simi-
larity of the reconstructed images and ground truth images.
Sample-level Semantics
We investigate the module of
sample-level semantics decoding from EEG signals on guid-
ing the denoising process. Models 1, 4, and 5 represent
the experimental results only using the saliency, both the
saliency map and sample-level semantics with the supervi-
sion of BLIP caption, and both the saliency map and sample-
level semantics with the supervision of label caption, respec-
tively. By comparing 1 with 4 and 1 with 5, the experimen-
tal results demonstrate that the use of sample-level seman-
tics significantly increases the semantic accuracy of recon-
structed images.
BLIP Captions vs Label Captions
We also compare the
two caption supervision methods with models 2 with 3 and
4 with 5. The experimental results of the label caption in all
metrics are superior to using BLIP caption. We impute these
results to that the EEG signals may only capture the class-
level information. So the prediction of BLIP latent is inaccu-
rate, which decreases the performance of diffusion models.
Conclusion
In this paper, we explore to understand the visually-evoked
brain activity. Specifically, We proposed a framework,
named NEUROIMAGEN, to reconstruct images of visual
perceptions from EEG signals. The NEUROIMAGEN first