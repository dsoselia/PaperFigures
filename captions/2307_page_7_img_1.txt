Figure 8: Differentiable NDP: MNIST network growth over 64 steps.
NDP in this paper are in fact often larger than the result-
ing policy networks. However, by running the developmen-
tal process longer, it is certainly possible to ultimately grow
policy networks with a larger number of parameters than the
underlying NDP. However, as the results in this paper sug-
gest, growing larger policy networks than necessary for the
tasks can have detrimental effects (Table 1b), so it will be
important to also learn when to stop growing. The exact in-
terplay between genome size, developmental steps, and task
performance constitutes important future work.
We will additionally extend the approach to more com-
plex domains and study in more detail the effects of growth
and self-organization on the type of neural networks that
evolution is able to discover. NDPs offer a unifying prin-
ciple that has the potential to capture many of the proper-
ties that are important for biological intelligence to strive
(Versace et al., 2018; Kudithipudi et al., 2022). While in-
nate structures in biological nervous systems have greatly in-
spired AI approaches (e.g. convolutional architectures being
the most prominent), how evolution discovered such wiring
diagrams and how they are grown through a genomic bottle-
neck are questions rarely addressed. In the future, NDPs
could consolidate a different pathway for training neural net-
works and lead to new methodologies for developing AI sys-
tems, beyond training and fine-tuning.
Acknowledgments
This project was supported by a GoodAI Research Award
and a European Research Council (ERC) grant (GA no.
101045094, project ”GROW-AI”)