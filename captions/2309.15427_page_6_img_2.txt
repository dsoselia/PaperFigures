Figure 3: Performance w.r.t. different number of GNN layers.
Figure 4: Performance w.r.t. different number of cross-
modality pooling layers.
performance while 4 layers perform the best for PubMedQA.
Second, the optimal number of GNN layers for 3B and 11B
LLMs differs. For example, for OBQA, 3 layers work best for
3B LLM, while 11B LLM reaches its top performance when
using 5 layers. Third, choosing different GNN layers can have
a weak impact on some datasets while can also drastically
affect the performance on other datasets. To demonstrate,
increasing from 3 layers to 5 layers for 11B LLM can
decrease the performance on ARC by a large margin (from
78.1 to 74.3), while adjusting the layers for BioASQ may not
lead to a big change in the performance.
Impact of cross-modality layers. To investigate the
influence of layer numbers in the cross-modality pooling
layer, we report the performance of different cross-modality
layers in Figure 4. As shown in the figure, we observe that
the commonsense reasoning dataset OBQA and biomedical
reasoning dataset BioASQ demonstrate different reactions
to layer numbers. Specifically, for OBQA, the performance
of the larger 11B LLM increases when increasing the cross-
modality layers, while the performance of the smaller 3B
LLM decreases. On the other hand, for BioASQ, the larger
11B LLM tends to show a degraded performance when
adding more layers, while the smaller 3B model presents
an improved performance. This indicates that suitable cross-
modality layers can lead to the best model performance.
Case Study and Visualization
For a more intuitive understanding and comparison, we
randomly select two examples from the OBQA dataset
and visualize the retrieved subgraphs in Figure 5. For
visualization clarity, we only show question entities and a
limited number of their neighbors. We remarkably notice that
the retrieved subgraphs encompass certain entities for the
correct answer, and there exist edges connecting the question
and answer entities, which makes the task of question
Figure 5: Case study on two QA examples from OBQA
dataset. Question entities are marked in green and their
subsampled neighbors in the KG are marked in blue. The
entities appearing in the correct answer are marked in orange.
answering easier by leveraging this information.
To answer the question “What is the best way to guess
a babies eye color?”, Prompt Tuning makes the wrong
generation “Just take a random guess”. On the other hand,
our retrieved subgraph offers the links that directly relate
the entity “babies” to “family”, “record”, and further to
“genealogy”, which all appear in the correct option (d). This
important context provides valuable insights for the model.
Note that the subgraph also contains irrelevant entities such
as “round” and “nursery”. This explains why directly using
the knowledge graph can introduce noise. However, our GNP
method possesses the capability to collect the most critical
information in the graph to determine the correct answer.
The second question “were there fossil fuels in the ground
when humans evolved?” requires correctly identifying the
historical sequencing order between the entity “humans” and
“fossil fuels”. The retrieved subgraph contains the critical
relation, i.e., “humans”, “evolve”, “prior”, “fossil fuel”.
Nevertheless, the subgraph also contains the entity “created”
that could confuse the model into selecting option (a). GNP
is able to capture the structural proximity among the key
entities and select the correct answer (c).
Conclusion
In this paper, we address the limitations of LLMs in precisely
capturing and returning grounded knowledge. In particular,
we propose Graph Neural Prompting (GNP), a novel plug-
and-play method to assist pre-trained LLMs in learning
beneficial knowledge from KGs. Extensive experiments on
commonsense and biomedical reasoning tasks demonstrate
that GNP can improve the performance by +13.5% when
LLM is frozen, and +1.8% when LLM is tuned. In addition,
we present ablation studies, model design comparison,
parameter sensitivity, case study and visualization to validate
the effectiveness of the proposed method.