KOSMOS-2.5: A Multimodal Literate Model
Tengchao Lv∗, Yupan Huang∗, Jingye Chen∗, Lei Cui∗†, Shuming Ma, Yaoyao Chang,
Shaohan Huang, Wenhui Wang, Li Dong, Weiyao Luo, Shaoxiang Wu, Guoxin Wang,
Cha Zhang, Furu Wei†
Microsoft
aka.ms/GeneralAI
Abstract
We present KOSMOS-2.5, a multimodal literate model for machine reading of text-
intensive images. Pre-trained on large-scale text-intensive images, KOSMOS-2.5
excels in two distinct yet cooperative transcription tasks: (1) generating spatially-
aware text blocks, where each block of text is assigned its spatial coordinates
within the image, and (2) producing structured text output that captures styles and
structures into the markdown format. This unified multimodal literate capability
is achieved through a shared Transformer architecture, task-specific prompts, and
flexible text representations. We evaluate KOSMOS-2.5 on end-to-end document-
level text recognition and image-to-markdown text generation. Furthermore, the
model can be readily adapted for any text-intensive image understanding task with
different prompts through supervised fine-tuning, making it a general-purpose tool
for real-world applications involving text-rich images. This work also paves the
way for the future scaling of multimodal large language models.
… [x_119] [y_306] [x_159] [y_319]: Type of 
[x_119] [y_323] [x_163] [y_336]: Disaster …
… | Type of Disaster | No. of disasters 
occurred | …
309.11419v1  [cs.CL]  20 Sep 2023