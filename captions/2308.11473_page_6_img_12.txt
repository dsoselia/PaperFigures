a marble bust of Thanos, highly detailed
Coarse NeRF
Refined NeRF
a DSLR photo of a Siamese cat, 4K, highly detailed
Coarse NeRF
Refined NeRF
Figure 5. IT3D can recover NeRF with mild geometry or Janus problem. Current text-to-3D methods are potentially to generate
failure cases like below examples, our method are capable of recovering failure cases with mild geometry or Janus problem.
Coarse NeRF
Refined NeRF
Dataset Generated by image-to-image Pipeline
a 3D model of an iron man
Image-to-Image
Discrimination Loss
Coarse Mesh
Edited Mesh
Dataset Generated by image-to-image Pipeline
Image-to-Image
a bunch of yellow rose
a bunch of blue rose
Discrimination Loss
a 3D model of an iron man
Figure 6. Examples for generated dataset. Our method can work on high-variance dataset and can tolerate failure cases of image-to-
image pipeline(see texture of iron man dataset)
Leveraging the diffusion prior empowers the generator to
closely track the discriminator’s updates at an accelerated
pace.
As a result, the discriminator can focus on learn-
ing higher-level distribution discrepancies without spending
time on mastering minute details. Consequently, both the
generator and discriminator update at significantly higher
speeds compared to traditional vanilla 3D GANs.
5. Experiments
5.1. Implementation details
As our baseline method, we opt for the default config-
uration of text-to-3D in the Stable DreamFusion reposi-
tory [21]. This baseline approach embraces classical SDS
loss and the regularization losses outlined in DreamFu-
sion [10]. It is noteworthy that our IT3D method serves as a
plug-and-play refinement technique and can also be seam-
lessly applied to any text-to-3D method based on 2D diffu-
sion priors.
For our baseline method, complex prompts such as
avatars typically require approximately 20k steps to achieve
complete convergence, while simpler prompts like flow-
ers converge around 15k steps. To ensure a fair compari-
son, we train the baseline method for 25K steps (1.5 to 2.5
GPU hours) to guarantee the full convergence of the 3D
model. As for our method, we resume training from 10k
to 20k steps of the baseline method, varying based on the
complexity of the prompt. Following the resumption and
dataset generation steps, we proceed to initialize a discrim-
inator using the same architecture as EG3D, commencing
our Diffusion-GAN dual training strategy.
It is important to note that the entire refinement process
is iterative in nature. After enhancing the 3D model’s qual-
ity, the same process of dataset generation and refinement
can be iteratively applied to the improved 3D model, re-
sulting in further quality improvements. Additionally, the
incorporation of a Dataset Update (DU) strategy [6,17] can
complement our training approach. But in this experiment,