Figure 1: A screenshot of the interface used to collect feedback for each step in
a solution.
math-relevant tokens, which we call MathMix.
Similar to Lewkowycz et al.
(2022), we find that this improves the modelâ€™s mathematical reasoning capabil-
ities. Details on how this dataset was constructed can be found in Appendix A.
2.3
Generator
To make parsing individual steps easier, we train the generator to produce
solutions in a newline delimited step-by-step format. Specifically, we few-shot
generate solutions to MATH training problems, filter to those that reach the
correct final answer, and finetune the base model on this dataset for a single
epoch. This step is not intended to teach the generator new skills; it is intended
only to teach the generator to produce solutions in the desired format.
2.4
Data Collection
To collect process supervision data, we present human data-labelers with step-
by-step solutions to MATH problems sampled by the large-scale generator.
Their task is to assign each step in the solution a label of positive, negative,
or neutral, as shown in Figure 1. A positive label indicates that the step is cor-
rect and reasonable. A negative label indicates that the step is either incorrect
or unreasonable. A neutral label indicates ambiguity. In practice, a step may
be labelled neutral if it is subtly misleading, or if it is a poor suggestion that
is technically still valid. We permit neutral labels since this allows us to defer
the decision about how to handle ambiguity: at test time, we can treat neutral
labels as either positive or negative. A more detailed description of the labelling
instructions is provided in Appendix D.
We label solutions exclusively from the large-scale generator in order to
maximize the value of our limited human-data resource. We refer to the en-
tire dataset of step-level labels collected as PRM800K. The PRM800K training
set contains 800K step-level labels across 75K solutions to 12K problems. To
4