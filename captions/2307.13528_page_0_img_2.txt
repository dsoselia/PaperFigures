FACTOOL: Factuality Detection in Generative AI
A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
I-Chun Chern2
Steffi Chern2
Shiqi Chen3
Weizhe Yuan4
Kehua Feng1
Chunting Zhou5
Junxian He6
Graham Neubig2
Pengfei Liu1,7∗
1Shanghai Jiao Tong University 2Carnegie Mellon University
3City University of Hong Kong 4New York University 5Meta AI
6The Hong Kong University of Science and Technology
7Shanghai Artificial Intelligence Laboratory
Abstract
The emergence of generative pre-trained mod-
els has facilitated the synthesis of high-quality
text, but it has also posed challenges in identi-
fying factual errors in the generated text. In
particular: (1) A wider range of tasks now
face an increasing risk of containing factual
errors when handled by generative models. (2)
Generated texts tend to be lengthy and lack a
clearly defined granularity for individual facts.
(3) There is a scarcity of explicit evidence avail-
able during the process of fact checking.
With the above challenges in mind, in this
paper, we propose FACTOOL, a task and do-
main agnostic framework for detecting factual
errors of texts generated by large language
models (e.g., ChatGPT). Experiments on four
different tasks (knowledge-based QA, code
generation, mathematical reasoning, and sci-
entific literature review) show the efficacy of
the proposed method. We release the code
of FACTOOL associated with ChatGPT plu-
gin interface at https://github.com/
GAIR-NLP/factool.
1
Introduction
Generative artificial intelligence (AI) technology,
exemplified by GPT-4 (OpenAI, 2023) consoli-
dates various tasks in natural language process-
ing into a single sequence generation problem.
This unified architecture enables users to complete
multiple tasks (e.g., question answering (Thop-
pilan et al., 2022), code generation (Chen et al.,
2021), math problem solving (Lewkowycz et al.,
2022), and scientific literature generation (Taylor
et al., 2022)) through a natural language inter-
face (Liu et al., 2023) with both unprecedented
performance (Bubeck et al., 2023) and interactiv-
ity.
However, at the same time, such a generative
paradigm also introduces some unique challenges.
∗Corresponding author
Claim
Extraction
Query
Generation
Verification
Self-check 
Claims
1. 
2. 
Evidence
Collection
Tool 
Querying 
Tools 
0
100
Factuality 
Evidence
Tool Queries
a. 
b. 
1
2
3
4
5
ChatGPT  
Response
Prompt
!
FacTool
Figure 1: Tool-augmented framework for factuality de-
tection.
Content that is automatically generated can of-
ten exhibit inaccuracies or deviations from the
truth due to the limited capacity of large language
models (LLMs) (Ji et al., 2023; Schulman, 2023).
LLMs are susceptible to producing content that
appears credible but may actually be factually in-
correct or imprecise. This limitation restricts the
application of generative AI in some high-stakes ar-
eas, such as healthcare, finance, and law. Therefore,
it is crucial to identify these errors systematically
to improve the usefulness and reliability of the gen-
erated content.
Current literature on detecting and mitigating
factual errors generated by machine learning mod-
els focuses predominantly on a single specific task,
for example, retrieval-augmented verification mod-
els for QA (Lewis et al., 2020), hallucination detec-
tion models for text summarization (Fabbri et al.,
2022), and execution-based evaluation for code
(Shi et al., 2022). While these methods have proven
successful within their respective areas, given the
remarkable versatility of tasks and domains han-
dled by LLMs, we argue that it is also important
arXiv:2307.13528v2  [cs.CL]  26 Jul 2023