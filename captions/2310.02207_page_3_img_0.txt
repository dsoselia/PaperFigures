Figure 2: Out-of-sample R2 for linear probes trained on every model, dataset, and layer.
probe, these representations are more accurate with increasing model scale, and the representations
smoothly increase in quality throughout the first half of the layers of the model before reaching a
plateau. These observations are consistent with results from the factual recall literature demonstrat-
ing that early-to-mid MLP layers are responsible for recalling information about factual subjects
(Meng et al., 2022a; Geva et al., 2023).
The dataset with the worst performance is the New York City dataset. This was expected given the
relative obscurity of most of the entities compared with other datasets. However, this is also the
dataset where the largest model has the best relative performance, at nearly 2x the R2 of smaller
models, suggesting that sufficiently large LLMs could eventually form detailed spatial models of
individual cities.
3 2
L
R