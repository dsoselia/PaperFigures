In this study, we investigated OpenAIs GPT-3.5 and GPT-4s ability to fact-check claims. We found that
GPT-4 outperformed GPT-3.5. Notably, even without contextual information, GPT-3.5 and GPT-4 demon-
strate good performance of 63-75% accuracy on average, which further improves to above 80% and 89%
for non-ambiguous verdicts when context is incorporated. Another crucial observation is the dependency
on the language of the prompt. For non-English fact-checking tasks, translated prompts frequently outper-
formed the originals, even if the related claims pertained to non-English speaking countries and retrieved
predominantly non-English information. The accuracy of these models ranged significantly across languages,
underscoring the importance of the original language of the claim.
Our results suggest that these models cannot completely replace human fact-checkers as being wrong even
10% of the time may have devastating implications in today’s information ecosystem. Therefore, integrating
mechanisms allowing for the verification of their verdict and reasoning is paramount. In particular, they
hold potential as tools for content moderation and accelerating human fact-checkers’ work. Looking ahead,
it is important to delve deeper into the conditions under which Large Language Models (LLMs) excel or
falter. As these models gain responsibilities in various high-stakes domains, it is crucial that their factual
reliability is well-understood and that they are deployed judiciously under human supervision. While our
study concentrated on OpenAI’s GPT-3.5 and GPT-4, the rapid evolution of the field means newer, possibly
fine-tuned, LLMs are emerging. One salient advantage of our methodology, distinguishing it from others,
is the LLM Agents’ capability to justify their conclusions. Future research should explore if, by critically
examining the reasons and references provided by the LLMs, users can enhance the models’ ability to fact-
check claims effectively.
Acknowledgements
The authors thank Fabrizio Gilardi, Emma Hoes, and Meysam Alizadeh for their valuable input that enriched
the quality of this work.
11