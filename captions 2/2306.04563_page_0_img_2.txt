ChatGPT is fun, but it is not funny!
Humor is still challenging Large Language Models
Sophie Jentzsch1 and Kristian Kersting2,3,4
1Institute for Software Technology, German Aerospace Center (DLR), Cologne, Germany
2Computer Science Department, Technical University Darmstadt, Darmstadt, Germany
3Centre for Cognitive Science, TU Darmstadt
4Hessian Center for AI (hessian.AI)
sophie.jentzsch@dlr.de, kersting@cs.tu-darmstadt.de
Abstract
Humor is a central aspect of human commu-
nication that has not been solved for artificial
agents so far. Large language models (LLMs)
are increasingly able to capture implicit and
contextual information. Especially, OpenAI’s
ChatGPT recently gained immense public at-
tention. The GPT3-based model almost seems
to communicate on a human level and can even
tell jokes. Humor is an essential component of
human communication. But is ChatGPT really
funny?
We put ChatGPT’s sense of humor to the test.
In a series of exploratory experiments around
jokes, i.e., generation, explanation, and detec-
tion, we seek to understand ChatGPT’s capabil-
ity to grasp and reproduce human humor. Since
the model itself is not accessible, we applied
prompt-based experiments.
Our empirical evidence indicates that jokes are
not hard-coded but mostly also not newly gen-
erated by the model. Over 90% of 1008 gener-
ated jokes were the same 25 Jokes. The system
accurately explains valid jokes but also comes
up with fictional explanations for invalid jokes.
Joke-typical characteristics can mislead Chat-
GPT in the classification of jokes. ChatGPT
has not solved computational humor yet but it
can be a big leap toward “funny” machines.
1
Introduction
For humans, humor plays a central role in forming
relationships and can enhance performance and mo-
tivation [16]. It is a powerful instrument to affect
emotion and guide attention [14]. Thus, a compu-
tational sense of humor holds the potential to mas-
sively boost human-computer interaction (HCI).
Unfortunately, although computational humor is a
longstanding research domain [26], the developed
machines are far from "funny." This problem is
even considered to be AI-complete [22].
Continuous advances and recent breakthroughs
in machine learning (ML), however, lead to an ever-
increasing panoply of applications [e.g., 15, 3] and
Why don't scientists trust atoms?
Because they make up everything!
Sure, here's a joke for you:
Tell me a joke, please! 
Figure 1: Exemplary illustration of a conversation be-
tween a human user and an artificial chatbot. The joke
is a true response to the presented prompt by ChatGPT.
likewise open new opportunities for natural lan-
guage processing (NLP). Transformer-based large
language models (LLMs) increasingly capture and
reflect implicit information, such as stereotypes [7],
moral [6], and humor [5, 25]. Humor is often im-
plicit and carried by subtle details. Thus these
novel qualities of LLMs give reason to hope for
new advances in artificial humor.
Most recently, OpenAI’s ChatGPT gained im-
mense attention for its unprecedented capabilities.
Users can interact with the model via public chat
API in a conversation-like course. The system is
able to answer a huge variety of questions while
taking the previous contextual conversation into
consideration. In fact, it can even tell jokes, as
displayed in Fig. 1. ChatGPT is fun and almost ap-
pears to interact on a human-like level. Yet, when
interacting with the model, users may quickly get
a glimpse of its limitations. Although ChatGPT
generates text in almost error-free English, gram-
matical glitches and content-related mistakes occur.
In the preceding exploration, we noticed that Chat-
GPT is likely to repeat the exact same jokes fre-
quently. Moreover, the provided jokes were strik-
ingly correct and sophisticated. These observations
led to the hypothesis that output jokes are not origi-
nally generated by the model. Instead, they seem
arXiv:2306.04563v1  [cs.AI]  7 Jun 2023